# Web Crawler

In diesem Repo wird ein einfacher Web-Crawler entwickelt.

Es werden Datenstrukturen und Funktionen definiert, um HTML-Seiten zu reprÃ¤sentieren
und auszuwerten, welche Links es darin gibt.
Die so definierten Objekte bilden einen Graphen, den man daraufhin untersuchen kann,
welche Seiten von einer Startseite aus erreichbar sind, wie viele Links auf eine Seite
zeigen etc., um dann auf dieser Grundlage eine einfache Suchmaschine zu bauen.
